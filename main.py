import os
import io
import re
import json
import streamlit as st
import networkx as nx
from gtts import gTTS
from difflib import get_close_matches
from dotenv import load_dotenv
from streamlit_mic_recorder import mic_recorder
import time
from pathlib import Path

# ==== LLM (LangChain) ====
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ==== OpenAI STT ====
from openai import OpenAI

# ===============================
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env)
# ===============================
# load_dotenv()


def get_secret(key: str, default: str = ""):
    try:
        return st.secrets.get(key, os.getenv(key, default))
    except Exception:
        return os.getenv(key, default)


OPENAI_API_KEY = get_secret("OPENAI_API_KEY")
OPENAI_MODEL = get_secret("OPENAI_MODEL", "gpt-4o-mini")
STT_MODEL = get_secret("STT_MODEL", "gpt-4o-mini-transcribe")
OPENAI_TTS_MODEL = get_secret("OPENAI_TTS_MODEL", "gpt-4o-mini-tts")
OPENAI_TTS_VOICE = get_secret("OPENAI_TTS_VOICE", "alloy")

# ===============================
# ì„¤ì • ìŠ¤ìœ„ì¹˜
# ===============================
USE_LLM_NORMALIZE = True  # LLM ë³´ì¡° ì •ê·œí™” ì‚¬ìš©
USE_SPEECH_TO_TEXT = True  # ìŒì„±(STT) ì‚¬ìš©


# ===============================
# ê³µí†µ ìœ í‹¸
# ===============================

st.set_page_config(
    page_title="ë‚¨ì–‘ì£¼ë„ì‹œê³µì‚¬ AI ê¸°ë°˜ ì‹¤ë‚´ ë„¤ë¹„ê²Œì´ì…˜",
    page_icon="ğŸ¢",
    layout="wide",  # âœ… í™”ë©´ í­ ë„“íˆê¸°
    initial_sidebar_state="collapsed",
)

# ë©”ì¸ ì»¨í…Œì´ë„ˆì˜ ìµœëŒ€ í­ í™•ì¥
st.markdown(
    """
<style>
/* ê¸°ë³¸ block-container í­ì„ ë„“í˜ (ì›í•˜ëŠ” ê°’ìœ¼ë¡œ ì¡°ì ˆ) */
.block-container {max-width: 1200px;}
@media (min-width: 1600px){ .block-container {max-width: 1400px;} }
</style>
""",
    unsafe_allow_html=True,
)


def stream_markdown(text: str, chunk: int = 6, delay: float = 0.02):
    """
    ì±„íŒ… ë§í’ì„  ë‚´ë¶€ì—ì„œ 'íƒ€ì íš¨ê³¼'ë¥¼ ë‚´ëŠ” ê°„ë‹¨ í•¨ìˆ˜.
    í˜„ì¬ ì»¨í…ìŠ¤íŠ¸(ì˜ˆ: with st.chat_message(...)) ì•ˆì—ì„œ í˜¸ì¶œí•´ì•¼ ë§í’ì„  ì•ˆì— ë Œë”ë¨.
    """
    placeholder = st.empty()
    buf = ""
    for i in range(0, len(text), chunk):
        buf += text[i : i + chunk]
        placeholder.markdown(buf)
        time.sleep(delay)


def fuzzy_match(user_text, poi_map):
    if not user_text:
        return None
    candidates = list(poi_map.keys())
    matches = get_close_matches(user_text, candidates, n=1, cutoff=0.6)
    return matches[0] if matches else None


def tts_advance(llm, text):
    if llm is None:
        return text
    prompt = ChatPromptTemplate.from_template(
        """
        ë‹¹ì‹ ì€ ê¸¸ ì•ˆë‚´ë¥¼ í•˜ê¸° ìœ„í•´ ì ì–´ì§„ {text}ì— ëŒ€í•´ ì¹œì ˆí•˜ê²Œ ë²ˆì—­í•˜ê³  ì•Œë ¤ì£¼ëŠ” ë„¤ë¹„ê²Œì´ì…˜ ì…ë‹ˆë‹¤.

        - ê·œì¹™
        1. "â†’" ëœ ëª¨ì–‘ì€ í™”ì‚´í‘œë¼ê³  ë²ˆì—­í•˜ì§€ë§ê³ , ì¼ë°˜ ìë™ì°¨ ë„¤ë¹„ê²Œì´ì…˜ì´ ë²ˆì—­í•˜ë“¯ì´ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•  ê²ƒ.
        2. ì „ì²´ì ìœ¼ë¡œ ë¬¸ë§¥ì´ ìì—°ìŠ¤ëŸ¬ìš´ì§€ í•œë²ˆ ë” í™•ì¸í•˜ê³ , ë§ì¶¤ë²• ê·¸ë¦¬ê³  ë„ì–´ì“°ê¸° ë§ˆì§€ë§‰ìœ¼ë¡œ ë¶€ë“œëŸ½ê²Œ ì½í˜€ì§€ëŠ”ì§€ í™•ì¸í•  ê²ƒ.
        3. ë¬¸ì¥ì€ ì „ì²´ì ìœ¼ë¡œ ì¹œì ˆí•  ê²ƒ
        4. ìš”ì²­í•œ ë¬¸êµ¬ì— ì—†ëŠ” ë‚´ìš©ë“¤ì€ í•¨ë¶€ë¡œ ì§€ì–´ë‚´ì§€ ë§ ê²ƒ.
        5. ë‚¨ìì™€ ì—¬ìê°€ êµ¬ë¶„ë˜ì–´ ìˆëŠ” ìƒ¤ì›Œì‹¤, í™”ì¥ì‹¤ì˜ ê²½ìš° í™•ì‹¤í•˜ê²Œ ë‚¨ìì™€ ì—¬ì êµ¬ë¶„ì§€ì–´ì„œ ì˜ ë“¤ë¦´ ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•  ê²ƒ.
        6. ì—˜ë¦¬ë² ì´í„°ê°€ ì—°ì†ìœ¼ë¡œ 1ì¸µ -> 2ì¸µ -> 3ì¸µ ì´ëŸ°ì‹ìœ¼ë¡œ ì´ì–´ì§ˆ ë•ŒëŠ” ì—˜ë¦¬ë² ì´í„° 1ì¸µ~3ì¸µê³¼ ê°™ì´ í•œë²ˆì— ì•ˆë‚´í• ê²ƒ.
        """
    )

    chain = prompt | llm | StrOutputParser()

    advanced_tts = chain.invoke({"text": text})

    return advanced_tts


def speak_openai(llm, client, text, filename="route.mp3"):
    out = Path(filename)
    with st.status("ğŸ”Š ì•ˆë‚´ ìŒì„± ìƒì„± ì¤‘...", expanded=True) as status:
        status.update(label="ğŸ“ ìŒì„± ëŒ€ë‹µì„ ìœ„í•´ ëŒ€ë‹µì„ ì •ë¦¬í•˜ëŠ” ì¤‘â€¦")
        polished = tts_advance(llm, text)
        status.update(label="ğŸ¤ ìŒì„± í•©ì„± ì¤‘â€¦")

        # ğŸ‘‡ format ì¸ì ì œê±°!
        with client.audio.speech.with_streaming_response.create(
            model=OPENAI_TTS_MODEL,
            voice=OPENAI_TTS_VOICE,
            input=polished,
        ) as resp:
            resp.stream_to_file(out)

        status.update(label="â–¶ï¸ ì¬ìƒí•©ë‹ˆë‹¤", state="complete")

    st.audio(str(out), format="audio/mp3", autoplay=True)


# ===============================
# ë°ì´í„° ë¡œë“œ ë° ê·¸ë˜í”„ êµ¬ì„±
# ===============================
with open("indoor_graph.json", "r", encoding="utf-8") as f:
    graph_data = json.load(f)["buildings"][0]

G = nx.Graph()
for e in graph_data["edges"]:
    G.add_edge(e["from"], e["to"], via=e["via"])

poi_map = {}
for floor in graph_data["floors"]:
    for p in floor["pois"]:
        name = p["name_ko"]
        poi_map[name] = p["id"]
        poi_map[name.replace(" ", "")] = p["id"]  # ê³µë°± ì œê±° í‚¤ë„ ë§¤í•‘


def id_to_name(node_id):
    return next(
        p["name_ko"]
        for floor in graph_data["floors"]
        for p in floor["pois"]
        if p["id"] == node_id
    )


def safe_find_route(start_name, end_name):
    if start_name not in poi_map:
        fm = fuzzy_match(start_name.replace(" ", ""), poi_map)
        if fm:
            start_name = fm
        else:
            return None, f"ì¶œë°œì§€ '{start_name}' ëŠ” ë“±ë¡ëœ ìœ„ì¹˜ê°€ ì•„ë‹™ë‹ˆë‹¤."

    if end_name not in poi_map:
        fm = fuzzy_match(end_name.replace(" ", ""), poi_map)
        if fm:
            end_name = fm
        else:
            return None, f"ë„ì°©ì§€ '{end_name}' ëŠ” ë“±ë¡ëœ ìœ„ì¹˜ê°€ ì•„ë‹™ë‹ˆë‹¤."

    try:
        path = nx.shortest_path(G, poi_map[start_name], poi_map[end_name])
        route = [id_to_name(node) for node in path]
        return route, None
    except nx.NetworkXNoPath:
        return None, f"{start_name}ì—ì„œ {end_name}ê¹Œì§€ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


# ===============================
# ê°„ë‹¨ POI ì¶”ì¶œê¸° (LLM ì—†ì´)
# ===============================
def extract_poi_candidate(text):
    if text in poi_map:
        return text
    t0 = text.replace(" ", "")
    if t0 in poi_map:
        return t0
    for token in re.split(r"[ ,.!?/~Â·()\[\]{}\"'â€œâ€â€™]+", text):
        token = token.strip()
        if not token:
            continue
        if token in poi_map:
            return token
        t1 = token.replace(" ", "")
        if t1 in poi_map:
            return t1
        fm = fuzzy_match(t1, poi_map)
        if fm:
            return fm
    return fuzzy_match(text.replace(" ", ""), poi_map)


# ===============================
# LLM ì¸ìŠ¤í„´ìŠ¤
# ===============================
llm = None
if USE_LLM_NORMALIZE:
    if not OPENAI_API_KEY:
        st.warning("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM ì •ê·œí™”ë¥¼ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.")
        USE_LLM_NORMALIZE = False
    else:
        llm = ChatOpenAI(model_name=OPENAI_MODEL, temperature=0, api_key=OPENAI_API_KEY)


# ===============================
# (ë³´ì¡°) LLM ì •ê·œí™”
# ===============================
def normalize_with_llm_fallback(text):
    cand = extract_poi_candidate(text)
    if cand:
        return cand
    if not USE_LLM_NORMALIZE or llm is None:
        return "ì•Œ ìˆ˜ ì—†ìŒ"

    poi_list = "\n".join(f"- {p}" for p in poi_map.keys())
    prompt = ChatPromptTemplate.from_template(
        """
        ì‚¬ìš©ìê°€ "{user_text}" ë¼ê³  ë§í–ˆìŠµë‹ˆë‹¤.

        ì‹¤ì œ í›„ë³´ POI ëª©ë¡:
        {poi_list}

        ê·œì¹™:
        - ì˜¤íƒ€/ë„ì–´ì“°ê¸°/ë°œìŒì´ ë¹„ìŠ·í•´ë„ 'í›„ë³´ ëª©ë¡' ì¤‘ ê°€ì¥ ì•Œë§ì€ 'í•œ í•­ëª©'ë§Œ ì •í™•íˆ ì¶œë ¥í•˜ì„¸ìš”.
        - í›„ë³´ ëª©ë¡ì— ì—†ëŠ” í‘œí˜„ì€ ì ˆëŒ€ ë‚´ì§€ ë§ˆì„¸ìš”.
        - ì •ë§ë¡œ ë§¤ì¹­ì´ ì–´ë µë‹¤ë©´ "ì•Œ ìˆ˜ ì—†ìŒ"ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        - ì¶œë ¥ì€ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œë§Œ (ë”°ì˜´í‘œ/ë§ˆí¬ë‹¤ìš´/JSON ê¸ˆì§€).
        """
    )
    chain = prompt | llm | StrOutputParser()
    try:
        response = chain.invoke({"user_text": text, "poi_list": poi_list}).strip()
        if response in poi_map:
            return response
        fm = fuzzy_match(response.replace(" ", ""), poi_map)
        return fm or "ì•Œ ìˆ˜ ì—†ìŒ"
    except Exception:
        return "ì•Œ ìˆ˜ ì—†ìŒ"


# ===============================
# ìŒì„±(STT) - OpenAI
# ===============================
oa_client = None
if USE_SPEECH_TO_TEXT:
    if not OPENAI_API_KEY:
        st.warning("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ STTê°€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        USE_SPEECH_TO_TEXT = False
    else:
        oa_client = OpenAI(api_key=OPENAI_API_KEY)


def transcribe_wav_bytes(wav_bytes: bytes) -> str:
    if not USE_SPEECH_TO_TEXT or oa_client is None:
        return ""
    bio = io.BytesIO(wav_bytes)
    bio.name = "speech.wav"
    result = oa_client.audio.transcriptions.create(
        model=STT_MODEL,
        file=bio,
        response_format="text",
        language="ko",
    )
    return (result or "").strip()


# ===============================
# UI
# ===============================

st.markdown(
    """
<style>
/* ì œëª© ì¤„ë°”ê¿ˆ & ë‹¨ì–´ê¹¨ì§ ì œì–´ */
h1, .stMarkdown h1 {
  white-space: normal !important;   /* í•œ ì¤„ ê³ ì • ë°©ì§€ */
  overflow-wrap: anywhere;          /* ë„ˆë¬´ ê¸´ ë‹¨ì–´ë„ ì ì ˆíˆ ì¤„ë°”ê¿ˆ */
  word-break: keep-all;             /* í•œêµ­ì–´ ìŒì ˆ ë‹¨ìœ„ ê¹¨ì§ ë°©ì§€ */
  text-wrap: balance;               /* (ì§€ì› ë¸Œë¼ìš°ì €) ë³´ê¸° ì¢‹ê²Œ ì¤„ ê· í˜• */
}
</style>
""",
    unsafe_allow_html=True,
)

# st.title ëŒ€ì‹ :
st.markdown("# ğŸ¢ ë‚¨ì–‘ì£¼ë„ì‹œê³µì‚¬ AI ê¸°ë°˜ ì‹¤ë‚´ ë„¤ë¹„ê²Œì´ì…˜")

st.caption(
    "1. í˜„ì¬ ìœ„ì¹˜ë¥¼ ë¬¼ì–´ë³¸ ë’¤, ëª©ì ì§€ë¥¼ ë¬»ëŠ” ìˆœì„œì¸ ì•ˆë‚´ ì ˆì°¨ì— ë§ê²Œ ë”°ë¼ì£¼ì„¸ìš”."
)
st.caption("2. í•´ë‹¹ ê±´ë¬¼ ì•ˆë‚´ê°€ ì•„ë‹Œ ì§ˆë¬¸ì„ í•  ê²½ìš°, ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ìŒì„± ì…ë ¥
st.subheader("ğŸ™ï¸ ìŒì„± ì…ë ¥")
audio = mic_recorder(
    start_prompt="ëˆŒëŸ¬ì„œ ë…¹ìŒ ì‹œì‘",
    stop_prompt="ëˆŒëŸ¬ì„œ ë…¹ìŒ ì •ì§€",
    just_once=False,
    use_container_width=True,
    format="wav",
)

spoken_text = None
if USE_SPEECH_TO_TEXT and audio and "bytes" in audio and audio["bytes"]:
    st.audio(audio["bytes"], format="audio/wav")
    with st.spinner("ìŒì„± ì¸ì‹ ì¤‘â€¦"):
        try:
            spoken_text = transcribe_wav_bytes(audio["bytes"])
            if spoken_text:
                st.success(f"ğŸ“ ì¸ì‹ ê²°ê³¼: {spoken_text}")
        except Exception as e:
            st.error(f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {e}")
            spoken_text = None

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "phase" not in st.session_state:
    st.session_state.phase = "ask_start"  # ask_start -> ask_end
if "current_start" not in st.session_state:
    st.session_state.current_start = None
if "current_end" not in st.session_state:
    st.session_state.current_end = None
if "asked_start_prompt" not in st.session_state:
    st.session_state.asked_start_prompt = False


# ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸
def phase_prompt():
    if st.session_state.phase == "ask_start":
        return "í˜„ì¬ ì–´ë””ì— ê³„ì‹ ê°€ìš”? (ì˜ˆ: ì •ë¬¸ ë¡œë¹„, ì²´ìœ¡ê´€ ì…êµ¬ ë“±)"
    elif st.session_state.phase == "ask_end":
        return "ì–´ë””ë¡œ ê°€ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? (ëª©ì ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”)"
    return "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”."


# ê¸°ì¡´ ëŒ€í™” ì¶œë ¥
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì–´ì‹œìŠ¤í„´íŠ¸ ì¸ì‚¬ 1íšŒ ì¶œë ¥
if st.session_state.phase == "ask_start" and not st.session_state.asked_start_prompt:
    start_prompt = "í˜„ì¬ ì–´ë””ì— ê³„ì‹ ê°€ìš”? ê·¼ì²˜ì— ë³´ì´ëŠ” ì‹œì„¤ë¬¼ì´ë‚˜ ê³„ì‹  ìœ„ì¹˜ë¥¼ ìì„¸íˆ ë§ì”€í•´ ì£¼ì„¸ìš”. (ì˜ˆ: 1ì¸µ ì•ˆë‚´ ë°ìŠ¤í¬)"
    st.session_state.messages.append({"role": "assistant", "content": start_prompt})
    with st.chat_message("assistant"):
        stream_markdown(start_prompt)
    st.session_state.asked_start_prompt = True

# ì…ë ¥ì°½
user_text_input = st.chat_input(
    "ì§ˆë¬¸ì— ë‹µì„ ì—¬ê¸°ì— ì…ë ¥í•´ ì£¼ì„¸ìš”."
)  # st.chat_input(phase_prompt())
user_input = spoken_text or user_text_input

# ì…ë ¥ ì²˜ë¦¬
if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # ========= 1ë‹¨ê³„: í˜„ì¬ ìœ„ì¹˜ =========
    if st.session_state.phase == "ask_start":
        start_candidate = normalize_with_llm_fallback(user_input)
        if start_candidate and start_candidate != "ì•Œ ìˆ˜ ì—†ìŒ":
            st.session_state.current_start = start_candidate
            st.session_state.phase = "ask_end"
            st.session_state.asked_start_prompt = False  # ë‹¤ìŒ ë¼ìš´ë“œ ì¸ì‚¬ ë¦¬ì…‹

            reply = (
                f"ì¶œë°œì§€ë¥¼ '{start_candidate}'ë¡œ ì„¤ì •í–ˆì–´ìš”. ì´ì œ ëª©ì ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."
            )
            st.session_state.messages.append({"role": "assistant", "content": reply})
            with st.chat_message("assistant"):
                stream_markdown(reply)

        else:
            reply = "ì£„ì†¡í•´ìš”, í˜„ì¬ ìœ„ì¹˜ë¥¼ ì˜ ëª» ë“¤ì—ˆì–´ìš”. ë“±ë¡ëœ ìœ„ì¹˜ëª…ìœ¼ë¡œ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”. (ì˜ˆ: ì •ë¬¸ ë¡œë¹„)"
            st.session_state.messages.append({"role": "assistant", "content": reply})
            with st.chat_message("assistant"):
                stream_markdown(reply)

    # ========= 2ë‹¨ê³„: ëª©ì ì§€ =========
    elif st.session_state.phase == "ask_end":
        end_candidate = normalize_with_llm_fallback(user_input)
        if end_candidate and end_candidate != "ì•Œ ìˆ˜ ì—†ìŒ":
            st.session_state.current_end = end_candidate

            start = st.session_state.current_start
            end = st.session_state.current_end

            route, error = safe_find_route(start, end)
            if error:
                reply = error
            else:
                route_text = " â†’ ".join(route)
                reply = (
                    f"{start}ì—ì„œ ì¶œë°œí•˜ì—¬ {end}ê¹Œì§€ ì´ë™ ê²½ë¡œëŠ” {route_text} ì…ë‹ˆë‹¤."
                )

            # ì´ˆê¸°í™” í›„ ask_startë¡œ ë³µê·€
            st.session_state.phase = "ask_start"
            st.session_state.current_start = None
            st.session_state.current_end = None
            st.session_state.asked_start_prompt = False

            st.session_state.messages.append({"role": "assistant", "content": reply})
            with st.chat_message("assistant"):
                stream_markdown(reply)
            if "ê²½ë¡œëŠ”" in reply:
                speak_openai(llm, oa_client, reply)

        else:
            reply = "ì£„ì†¡í•´ìš”, ëª©ì ì§€ë¥¼ ì˜ ëª» ë“¤ì—ˆì–´ìš”. ë“±ë¡ëœ ëª©ì ì§€ë¡œ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”. (ì˜ˆ: í™”ì¥ì‹¤ ë‚¨(1ì¸µ))"
            st.session_state.messages.append({"role": "assistant", "content": reply})
            with st.chat_message("assistant"):
                stream_markdown(reply)
